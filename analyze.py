#!/usr/bin/env python
'''	Parse data from primary.py (raw data is number of occurrences of candidate names per journal)
	Open each data file (csv) generated by primary.py as data_sets.
	Sort data into journal-dependent timelines and query-dependent averages (all journals per query)
	Plot using matplotlib
'''
import subprocess
from datetime import datetime
import calendar
import numpy as np

import matplotlib as mpl
mpl.use('TkAgg')
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib import gridspec as gs
mpl.rc('figure',facecolor='white')
from pylab import rcParams
rcParams['figure.figsize'] = 17, 13


def journal_timelines_maker(journal_timelines,this_data):
	for row in this_data:
		row_nums = [float(x) for x in row[1:]]
		if sum(row_nums):												#avoid division by zero if zero name occurrences
			row_nums = [int(1000.*x/sum(row_nums))/10. for x in row_nums]		
		if not len(journal_timelines[row[0]]):			
			journal_timelines[row[0]] = np.array([row_nums])							#not populated, initialize array			
		else:
			journal_timelines[row[0]] = np.vstack([journal_timelines[row[0]],row_nums])	#found populated, stack new row
	return journal_timelines

#-----plot journal_timelines-----#
def graph_journal_timelines(journal_timelines,num_files):
	#-----place hashtag before names to hide their data-----#
	show_names = '''
			clinton,
			sanders,
			trump,
			#cruz,
			#kasich'''
	#type = 'plot'
	type='scatter'
	name_map = [1 if x and x[0] != '#' else 0 for x in show_names.replace('\n','').replace('\t','').split(',') ]
	color_map = 'blue green red yellow orange'.split(' ')	
	plot_names = ' vs. '.join([x for x in show_names.replace('\n','').replace('\t','').split(',') if x and x[0] != '#'])
	
	for journal in journal_timelines.iterkeys():	
		for i in range(5):
			if name_map[i]:
				eval('plt.'+type+'(range(num_files),journal_timelines[journal][:,'+str(i)+'],color=\''+str(color_map[i])+'\',alpha=.15,label=\''+plot_names[i]+'\')')
	
	plt.title(plot_names+':\n % name occurrence for each journal')
	
	#----format date msg for x label
	year,month,day= str(datetime.now()).split()[0].split('-')
	date_msg='Query number (March 24, 2016 - '+calendar.month_name[int(month)]+' '+day+', '+year+')'
	
	plt.xlabel(date_msg,fontsize=14)
	plt.ylabel('% name each journal',fontsize=14)
	
	ax = plt.subplot()
	ax.set_axis_bgcolor('white')
	
	Clinton, = plt.plot([], label='Clinton')
	Sanders, = plt.plot([], label='Sanders')
	Trump, = plt.plot([], label='Trump')
	plt.legend(handles=[Clinton, Sanders, Trump])
	
	plt.tight_layout()
	
	plt.savefig('media/jt_'+str(datetime.now()).split('.')[0].replace(' ','_')+'.png')
	#plt.show()

#-----main-----#
def main():
	#open relevant files and append each data-set to data_sets
	files = subprocess.Popen(['ls data'],stdout=subprocess.PIPE,shell=True).communicate()[0].split('\n')
	files = [x for x in files if x[:4] == 'dat2']
	num_files = len(files)
	data_sets = []
	for file in files:	
		with open('data/'+file,'r') as f:
			data_sets.append(f.read())	
	
	#-----definitions-----#
	curr_cand = 'clinton sanders trump cruz kasich'.split(' ')
	with open('news_sites.txt','r') as f:
		journals = f.read().split('\n')[::2]
	journal_timelines = {journal:np.array([]) for journal in journals}
	coll_totals = []
	raw_totals = []
	coll_percents = []
	
	for data in data_sets:
			#parse each data set
		this_data = np.array([x.split(',')[0:6] for x in data.split('\n')[1:-2]])	
			#add each data set to journal-dependent timeline
		journal_timelines = journal_timelines_maker(journal_timelines,this_data)
			#remove journal label and convert to integer matrix
		this_data = this_data[:,1:].astype('i1')					
		single_coll_total = [sum(this_data[:,x]) for x in range(len(curr_cand))]
		coll_totals.append(single_coll_total)				#total mentions for each candidate in all journals per query
		
		#graph journal-dependent data
	graph_journal_timelines(journal_timelines,num_files)
	
	#--------get percentage appearances---------#
	for i in coll_totals:
		all_cand_sum = sum(i)
		coll_percents.append([int(1000.*x/all_cand_sum)/10. for x in i])
	coll_percents = np.array(coll_percents)

	avg_percents = [int(10*sum(coll_percents[:,x])/num_files)/10. for x in range(5)]
	print np.array(avg_percents),'(avg)'
	#--------end get percentage appearances---------#
	
	
	#----------------------start plotting averages---------------------------#
	fig = plt.figure()
	ax = fig.add_subplot(111)
	ax1=fig.add_subplot(331)
	ax2=fig.add_subplot(334)
	ax3=fig.add_subplot(335,sharey=ax2)
		
	for i in range(4):
		ax.spines['top bottom left right'.split(' ')[i]].set_color('none')
	ax.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')
	
	color_map = 'blue,green,red,cyan,magenta'.split(',')
	
	
		#-----plot averages-------#
	coll_totals = np.array(coll_totals)
	for cand in range(len(curr_cand)):
		ax1.plot(range(len(files)),coll_percents[:,cand],label=curr_cand[cand],color=color_map[cand])		
		ax2.plot(range(len(files)),coll_totals[:,cand],label=curr_cand[cand],color=color_map[cand])
	
	box = ax1.get_position()
	ax1.set_position([box.x0, box.y0, box.width * 1, box.height])
	box = ax2.get_position()
	ax2.set_position([box.x0, box.y0, box.width * 1, box.height])
	box = ax3.get_position()
	ax3.set_position([box.x0, box.y0, box.width * 1, box.height])

	#----legend----#
	ax1.legend(loc='upper left', bbox_to_anchor=(1, 1),fontsize=12,numpoints=1)
	
	#-----titles and labels-----#
	font_size = 12
	
	ax1.set_title('avg. percent appearances',fontsize=font_size)
	ax1.set_ylabel('avg. percent')
	
	ax2.set_title('raw totals from collected data',fontsize=font_size)
	ax2.set_ylabel('raw numbers')
	
	#----format date msg for x label
	
	#plt.tight_layout()

	#--------plot trendlines--------#
	#'''
	from trendline import trendline
	ax3.set_title('linear trendlines from raw data',fontsize=font_size)
	
	coll_total_trendlines = []
	for cand in range(len(curr_cand)):
		y_vals = coll_totals[:,cand]
		xy_array = np.array([[x,y_vals[x]] for x in range(len(y_vals))])
		th0,th1 = trendline.get_trendline(xy_array)	
		ax3.plot([0,len(files)],[th0,th1*len(files)+th0],label=curr_cand[cand]+' '+str(th1),color=color_map[cand])

	ax3.legend(loc='right',bbox_to_anchor=(1.6, .7),fontsize=12,numpoints=1,title='slope data') #legend
	#'''
	#--------end plot trendlines--------#
	
	#-------------plot moving averages----------------#
	
	
		#--------simple moving averages--------#
	ax4=fig.add_subplot(337,sharey=ax2)
	ax4.set_title('simple moving averages',fontsize=font_size)
	ax4.set_ylabel('based on raw numbers')
	
	simple_moving_averages=np.array([coll_totals[0],coll_totals[1],coll_totals[2]])
	for i in range(3,len(coll_totals)-3):
		simple_moving_averages=np.vstack(( simple_moving_averages, (  sum([coll_totals[x] for x in range(i-3,i+4)])  )/7))				
	for cand in range(len(curr_cand)):
		ax4.plot(range(len(simple_moving_averages)),simple_moving_averages[:,cand],label=curr_cand[cand],color=color_map[cand])
		#--------end simple moving averages--------#
	
	
		#--------cumulative moving averages--------#
	ax5=fig.add_subplot(338,sharey=ax2)
	ax5.set_title('cumulative moving averages',fontsize=font_size)
	
	cum_moving_averages=np.array([coll_totals[0]])
	for i in range(1,len(coll_totals)):
		cum_moving_averages=np.vstack(( cum_moving_averages,  (cum_moving_averages[i-1]*(i) + coll_totals[i])/(i+1)  ))
	for cand in range(len(curr_cand)):
		ax5.plot( range(len(files)),cum_moving_averages[:,cand],label=curr_cand[cand],color=color_map[cand] )
		#--------end cumulative moving averages--------#
	
	
	#----------------plot show----------------#
	year,month,day= str(datetime.now()).split()[0].split('-')
	date_msg='Query number (March 24, 2016 - '+calendar.month_name[int(month)]+' '+day+', '+year+')'
	#plt.title(date_msg)
	ax.set_xlabel(date_msg)
	
	plt.savefig('media/primary_'+str(datetime.now()).split('.')[0].replace(' ','_')+'.png'  )
	#plt.show()
	
if __name__ == '__main__':
	main()